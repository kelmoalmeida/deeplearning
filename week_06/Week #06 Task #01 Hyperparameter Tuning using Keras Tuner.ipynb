{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Week #06 Task #01 Hyperparameter Tuning using Keras Tuner.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DLkQmFwhbq4"
      },
      "source": [
        "# A brief recap about DL Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH2FWhOPNzZO"
      },
      "source": [
        "- Define the task\n",
        "  - Frame the problem\n",
        "  - Collect a dataset\n",
        "  - Understand your data\n",
        "  - Choose a measure of success\n",
        "- Develop a model\n",
        "  - Prepare the data\n",
        "  - Choose an evaluation protocol\n",
        "  - Beat a baseline\n",
        "  - Scale up: develop a model that overfits\n",
        "  - Regularize and tune your model\n",
        "- Deploy your model\n",
        "  - Explain your work to stakeholders and set expectations\n",
        "    - Ship an inference model\n",
        "    - Deploying a model as a rest API\n",
        "    - Deploying a model on device\n",
        "    - Deploying a model in the browser\n",
        "  - Monitor your model in the wild\n",
        "  - Maintain your model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTShha8tLAvY"
      },
      "source": [
        "# 1.0 Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD1hMKLZEObd"
      },
      "source": [
        "## 1.1 Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MR6rLenKnry"
      },
      "source": [
        "Install and import the Keras Tuner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEYDnz5LKra8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05f2b64-9f37-4ff3-9082-3aa6e3bfab75"
      },
      "source": [
        "# pip install -q (quiet)\n",
        "!pip install git+https://github.com/keras-team/keras-tuner.git -q"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-tuner (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtGJ6_Pi2yG9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import time\n",
        "import datetime\n",
        "import pytz\n",
        "import IPython\n",
        "import keras_tuner as kt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccfIzxFaHeOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5161c1dc-6147-4fa0-c041-7f1c0a2c19da"
      },
      "source": [
        "print('TF version:', tf.__version__)\n",
        "print('KT version:', kt.__version__)\n",
        "print('GPU devices:', tf.config.list_physical_devices('GPU'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.17.0\n",
            "KT version: 1.4.7\n",
            "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WGGeZQGESGP"
      },
      "source": [
        "## 1.2 Utils Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw9z0s-QqSCd"
      },
      "source": [
        "# download train_catvnoncat.h5\n",
        "!gdown 'https://github.com/terrematte/deeplearning/raw/refs/heads/main/datasets/cats/train_catvnoncat.h5'\n",
        "\n",
        "# download test_catvnoncat.h5\n",
        "!gdown 'https://github.com/terrematte/deeplearning/raw/refs/heads/main/datasets/cats/test_catvnoncat.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJYkR70dEGHh"
      },
      "source": [
        "def load_dataset():\n",
        "    # load the train data\n",
        "    train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
        "\n",
        "    # your train set features\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
        "\n",
        "    # your train set labels\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
        "\n",
        "    # load the test data\n",
        "    test_dataset = h5py.File('test_catvnoncat.h5', \"r\")\n",
        "\n",
        "    # your test set features\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
        "\n",
        "    # your test set labels\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
        "\n",
        "    # the list of classes\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:])\n",
        "\n",
        "    # reshape the test data\n",
        "    train_set_y_orig = train_set_y_orig.reshape((train_set_y_orig.shape[0],1))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((test_set_y_orig.shape[0],1))\n",
        "\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exIeT2zMHhxa"
      },
      "source": [
        "## 1.3 Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjQYsrdPHSyh"
      },
      "source": [
        "# Loading the data (cat/non-cat)\n",
        "train_set_x_orig, train_y, test_set_x_orig, test_y, classes = load_dataset()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ihL83MbHlhc"
      },
      "source": [
        "# Reshape the training and test examples\n",
        "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1)\n",
        "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1)\n",
        "\n",
        "# Standardize the dataset\n",
        "train_x = train_set_x_flatten/255\n",
        "test_x = test_set_x_flatten/255"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQn-Brt-IhK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f39135a-697a-46d4-d81c-79ecd821f551"
      },
      "source": [
        "print (\"train_x shape: \" + str(train_x.shape))\n",
        "print (\"train_y shape: \" + str(train_y.shape))\n",
        "print (\"test_x  shape: \" + str(test_x.shape))\n",
        "print (\"test_y  shape: \" + str(test_y.shape))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x shape: (209, 12288)\n",
            "train_y shape: (209, 1)\n",
            "test_x  shape: (50, 12288)\n",
            "test_y  shape: (50, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa9dcSRx1__x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "a5a8538c-6359-4b00-9d04-3fc3c658bf9b"
      },
      "source": [
        "# visualize a sample data\n",
        "index = 13\n",
        "plt.imshow(train_set_x_orig[index])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7cb8cc1b9e10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zLrb3ORIlo_"
      },
      "source": [
        "## 1.4 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJutkmXnIpG6"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_train_begin(self, batch, logs=None):\n",
        "    self.begins = time.time()\n",
        "    print('Training: begins at {}'.format(datetime.datetime.now(pytz.timezone('America/Fortaleza')).strftime(\"%a, %d %b %Y %H:%M:%S\")))\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    print('Training: ends at {}'.format(datetime.datetime.now(pytz.timezone('America/Fortaleza')).strftime(\"%a, %d %b %Y %H:%M:%S\")))\n",
        "    print('Duration: {:.2f} seconds'.format(time.time() - self.begins))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyfcUdH36lGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde42486-cb19-43bd-82b1-217e698dbeda"
      },
      "source": [
        "# Instantiate a simple classification model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(8, activation=tf.nn.relu, dtype='float64'),\n",
        "  tf.keras.layers.Dense(8, activation=tf.nn.relu, dtype='float64'),\n",
        "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid, dtype='float64')\n",
        "])\n",
        "\n",
        "# Instantiate a logistic loss function that expects integer targets.\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# Instantiate an accuracy metric.\n",
        "accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "# Instantiate an optimizer.\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "\n",
        "# configure the optimizer, loss, and metrics to monitor.\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])\n",
        "\n",
        "# training\n",
        "history = model.fit(x=train_x,\n",
        "                    y=train_y,\n",
        "                    batch_size=32,\n",
        "                    epochs=500,\n",
        "                    validation_data=(test_x,test_y),\n",
        "                    callbacks=[MyCustomCallback()],\n",
        "                    verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: begins at Sun, 03 Nov 2024 14:38:32\n",
            "Epoch 1/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 895ms/step - binary_accuracy: 0.4202 - loss: 0.7155 - val_binary_accuracy: 0.4400 - val_loss: 0.7047\n",
            "Epoch 2/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - binary_accuracy: 0.5613 - loss: 0.6901 - val_binary_accuracy: 0.3400 - val_loss: 0.7247\n",
            "Epoch 3/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.6181 - loss: 0.6766 - val_binary_accuracy: 0.3400 - val_loss: 0.7440\n",
            "Epoch 4/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.5993 - loss: 0.6762 - val_binary_accuracy: 0.3400 - val_loss: 0.7694\n",
            "Epoch 5/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6364 - loss: 0.6661 - val_binary_accuracy: 0.3400 - val_loss: 0.7871\n",
            "Epoch 6/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6742 - loss: 0.6514 - val_binary_accuracy: 0.3400 - val_loss: 0.8022\n",
            "Epoch 7/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6465 - loss: 0.6533 - val_binary_accuracy: 0.3400 - val_loss: 0.8111\n",
            "Epoch 8/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6453 - loss: 0.6421 - val_binary_accuracy: 0.3400 - val_loss: 0.8184\n",
            "Epoch 9/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6195 - loss: 0.6595 - val_binary_accuracy: 0.3400 - val_loss: 0.8272\n",
            "Epoch 10/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6658 - loss: 0.6375 - val_binary_accuracy: 0.3400 - val_loss: 0.8348\n",
            "Epoch 11/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6874 - loss: 0.6248 - val_binary_accuracy: 0.3400 - val_loss: 0.8332\n",
            "Epoch 12/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6701 - loss: 0.6292 - val_binary_accuracy: 0.3400 - val_loss: 0.8359\n",
            "Epoch 13/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6564 - loss: 0.6404 - val_binary_accuracy: 0.3400 - val_loss: 0.8355\n",
            "Epoch 14/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.6280 - loss: 0.6491 - val_binary_accuracy: 0.3400 - val_loss: 0.8298\n",
            "Epoch 15/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6591 - loss: 0.6397 - val_binary_accuracy: 0.3400 - val_loss: 0.8338\n",
            "Epoch 16/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6048 - loss: 0.6607 - val_binary_accuracy: 0.3400 - val_loss: 0.8462\n",
            "Epoch 17/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6053 - loss: 0.6655 - val_binary_accuracy: 0.3400 - val_loss: 0.8617\n",
            "Epoch 18/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6460 - loss: 0.6340 - val_binary_accuracy: 0.3400 - val_loss: 0.8511\n",
            "Epoch 19/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6821 - loss: 0.6162 - val_binary_accuracy: 0.3400 - val_loss: 0.8376\n",
            "Epoch 20/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6475 - loss: 0.6385 - val_binary_accuracy: 0.3400 - val_loss: 0.8374\n",
            "Epoch 21/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6496 - loss: 0.6285 - val_binary_accuracy: 0.3400 - val_loss: 0.8264\n",
            "Epoch 22/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6833 - loss: 0.6163 - val_binary_accuracy: 0.3400 - val_loss: 0.8212\n",
            "Epoch 23/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6594 - loss: 0.6337 - val_binary_accuracy: 0.3400 - val_loss: 0.8267\n",
            "Epoch 24/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6575 - loss: 0.6295 - val_binary_accuracy: 0.3400 - val_loss: 0.8314\n",
            "Epoch 25/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6504 - loss: 0.6251 - val_binary_accuracy: 0.3400 - val_loss: 0.8415\n",
            "Epoch 26/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6706 - loss: 0.6152 - val_binary_accuracy: 0.3400 - val_loss: 0.8320\n",
            "Epoch 27/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6747 - loss: 0.6137 - val_binary_accuracy: 0.3400 - val_loss: 0.8319\n",
            "Epoch 28/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6630 - loss: 0.6214 - val_binary_accuracy: 0.3400 - val_loss: 0.8197\n",
            "Epoch 29/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6861 - loss: 0.6096 - val_binary_accuracy: 0.3400 - val_loss: 0.8163\n",
            "Epoch 30/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6650 - loss: 0.6126 - val_binary_accuracy: 0.3400 - val_loss: 0.7987\n",
            "Epoch 31/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6425 - loss: 0.6276 - val_binary_accuracy: 0.3400 - val_loss: 0.8058\n",
            "Epoch 32/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6759 - loss: 0.6061 - val_binary_accuracy: 0.3400 - val_loss: 0.8097\n",
            "Epoch 33/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6533 - loss: 0.6189 - val_binary_accuracy: 0.3400 - val_loss: 0.8181\n",
            "Epoch 34/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6625 - loss: 0.6138 - val_binary_accuracy: 0.3400 - val_loss: 0.8248\n",
            "Epoch 35/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6122 - loss: 0.6376 - val_binary_accuracy: 0.3400 - val_loss: 0.8294\n",
            "Epoch 36/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6513 - loss: 0.6249 - val_binary_accuracy: 0.3400 - val_loss: 0.8315\n",
            "Epoch 37/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6551 - loss: 0.6123 - val_binary_accuracy: 0.3400 - val_loss: 0.8169\n",
            "Epoch 38/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6610 - loss: 0.6113 - val_binary_accuracy: 0.3400 - val_loss: 0.8181\n",
            "Epoch 39/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6640 - loss: 0.6075 - val_binary_accuracy: 0.3400 - val_loss: 0.8209\n",
            "Epoch 40/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6869 - loss: 0.5914 - val_binary_accuracy: 0.3400 - val_loss: 0.8092\n",
            "Epoch 41/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6544 - loss: 0.6099 - val_binary_accuracy: 0.3400 - val_loss: 0.8160\n",
            "Epoch 42/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6634 - loss: 0.6083 - val_binary_accuracy: 0.3400 - val_loss: 0.8126\n",
            "Epoch 43/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6931 - loss: 0.5894 - val_binary_accuracy: 0.3400 - val_loss: 0.8058\n",
            "Epoch 44/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6540 - loss: 0.6090 - val_binary_accuracy: 0.3400 - val_loss: 0.8035\n",
            "Epoch 45/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6318 - loss: 0.6175 - val_binary_accuracy: 0.3400 - val_loss: 0.8110\n",
            "Epoch 46/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6514 - loss: 0.6054 - val_binary_accuracy: 0.3400 - val_loss: 0.8285\n",
            "Epoch 47/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6668 - loss: 0.6031 - val_binary_accuracy: 0.3400 - val_loss: 0.8241\n",
            "Epoch 48/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7057 - loss: 0.5716 - val_binary_accuracy: 0.3400 - val_loss: 0.8055\n",
            "Epoch 49/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6674 - loss: 0.6032 - val_binary_accuracy: 0.3400 - val_loss: 0.8078\n",
            "Epoch 50/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6700 - loss: 0.5969 - val_binary_accuracy: 0.3400 - val_loss: 0.8103\n",
            "Epoch 51/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.6875 - loss: 0.5751 - val_binary_accuracy: 0.3400 - val_loss: 0.7990\n",
            "Epoch 52/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.6559 - loss: 0.6046 - val_binary_accuracy: 0.3400 - val_loss: 0.8070\n",
            "Epoch 53/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.6260 - loss: 0.6128 - val_binary_accuracy: 0.3400 - val_loss: 0.8147\n",
            "Epoch 54/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7037 - loss: 0.5759 - val_binary_accuracy: 0.3400 - val_loss: 0.7994\n",
            "Epoch 55/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6688 - loss: 0.5858 - val_binary_accuracy: 0.3400 - val_loss: 0.7975\n",
            "Epoch 56/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6724 - loss: 0.5870 - val_binary_accuracy: 0.3400 - val_loss: 0.8079\n",
            "Epoch 57/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6471 - loss: 0.6017 - val_binary_accuracy: 0.3400 - val_loss: 0.8092\n",
            "Epoch 58/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6624 - loss: 0.5903 - val_binary_accuracy: 0.3400 - val_loss: 0.8113\n",
            "Epoch 59/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6996 - loss: 0.5677 - val_binary_accuracy: 0.3400 - val_loss: 0.7856\n",
            "Epoch 60/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6134 - loss: 0.6139 - val_binary_accuracy: 0.3400 - val_loss: 0.8094\n",
            "Epoch 61/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6498 - loss: 0.5896 - val_binary_accuracy: 0.3400 - val_loss: 0.8220\n",
            "Epoch 62/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6337 - loss: 0.6077 - val_binary_accuracy: 0.3400 - val_loss: 0.8190\n",
            "Epoch 63/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6481 - loss: 0.6058 - val_binary_accuracy: 0.3400 - val_loss: 0.8100\n",
            "Epoch 64/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6447 - loss: 0.5887 - val_binary_accuracy: 0.3400 - val_loss: 0.8023\n",
            "Epoch 65/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.6464 - loss: 0.5952 - val_binary_accuracy: 0.3400 - val_loss: 0.8146\n",
            "Epoch 66/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6359 - loss: 0.5952 - val_binary_accuracy: 0.3400 - val_loss: 0.8170\n",
            "Epoch 67/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6509 - loss: 0.5938 - val_binary_accuracy: 0.3400 - val_loss: 0.7962\n",
            "Epoch 68/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6491 - loss: 0.5928 - val_binary_accuracy: 0.3400 - val_loss: 0.7840\n",
            "Epoch 69/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6237 - loss: 0.6046 - val_binary_accuracy: 0.3400 - val_loss: 0.7852\n",
            "Epoch 70/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.6820 - loss: 0.5574 - val_binary_accuracy: 0.3400 - val_loss: 0.7869\n",
            "Epoch 71/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6946 - loss: 0.5591 - val_binary_accuracy: 0.3400 - val_loss: 0.7713\n",
            "Epoch 72/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6519 - loss: 0.5874 - val_binary_accuracy: 0.3400 - val_loss: 0.7817\n",
            "Epoch 73/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.6816 - loss: 0.5681 - val_binary_accuracy: 0.3400 - val_loss: 0.7752\n",
            "Epoch 74/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6682 - loss: 0.5774 - val_binary_accuracy: 0.3400 - val_loss: 0.7566\n",
            "Epoch 75/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.6899 - loss: 0.5583 - val_binary_accuracy: 0.3400 - val_loss: 0.7614\n",
            "Epoch 76/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7027 - loss: 0.5557 - val_binary_accuracy: 0.3600 - val_loss: 0.7455\n",
            "Epoch 77/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6917 - loss: 0.5571 - val_binary_accuracy: 0.3200 - val_loss: 0.7478\n",
            "Epoch 78/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.6863 - loss: 0.5765 - val_binary_accuracy: 0.3400 - val_loss: 0.7748\n",
            "Epoch 79/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.6842 - loss: 0.5756 - val_binary_accuracy: 0.3400 - val_loss: 0.7825\n",
            "Epoch 80/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.6318 - loss: 0.5976 - val_binary_accuracy: 0.3400 - val_loss: 0.8190\n",
            "Epoch 81/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7302 - loss: 0.5235 - val_binary_accuracy: 0.3400 - val_loss: 0.7615\n",
            "Epoch 82/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7077 - loss: 0.5571 - val_binary_accuracy: 0.3400 - val_loss: 0.7728\n",
            "Epoch 83/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6503 - loss: 0.5789 - val_binary_accuracy: 0.3400 - val_loss: 0.7715\n",
            "Epoch 84/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6874 - loss: 0.5645 - val_binary_accuracy: 0.3400 - val_loss: 0.7767\n",
            "Epoch 85/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6624 - loss: 0.5726 - val_binary_accuracy: 0.3600 - val_loss: 0.7693\n",
            "Epoch 86/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6615 - loss: 0.5805 - val_binary_accuracy: 0.3400 - val_loss: 0.7954\n",
            "Epoch 87/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6730 - loss: 0.5643 - val_binary_accuracy: 0.3400 - val_loss: 0.7912\n",
            "Epoch 88/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6612 - loss: 0.5732 - val_binary_accuracy: 0.3400 - val_loss: 0.7787\n",
            "Epoch 89/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6865 - loss: 0.5404 - val_binary_accuracy: 0.3200 - val_loss: 0.7495\n",
            "Epoch 90/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6905 - loss: 0.5506 - val_binary_accuracy: 0.3400 - val_loss: 0.7736\n",
            "Epoch 91/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6870 - loss: 0.5540 - val_binary_accuracy: 0.3600 - val_loss: 0.7814\n",
            "Epoch 92/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6633 - loss: 0.5637 - val_binary_accuracy: 0.3600 - val_loss: 0.7887\n",
            "Epoch 93/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6855 - loss: 0.5523 - val_binary_accuracy: 0.3600 - val_loss: 0.7958\n",
            "Epoch 94/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6964 - loss: 0.5424 - val_binary_accuracy: 0.3600 - val_loss: 0.7634\n",
            "Epoch 95/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6962 - loss: 0.5546 - val_binary_accuracy: 0.3600 - val_loss: 0.7811\n",
            "Epoch 96/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6910 - loss: 0.5467 - val_binary_accuracy: 0.3600 - val_loss: 0.7753\n",
            "Epoch 97/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7049 - loss: 0.5317 - val_binary_accuracy: 0.3400 - val_loss: 0.7387\n",
            "Epoch 98/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7053 - loss: 0.5547 - val_binary_accuracy: 0.3400 - val_loss: 0.7380\n",
            "Epoch 99/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6853 - loss: 0.5561 - val_binary_accuracy: 0.3600 - val_loss: 0.7842\n",
            "Epoch 100/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7117 - loss: 0.5298 - val_binary_accuracy: 0.3600 - val_loss: 0.7693\n",
            "Epoch 101/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6946 - loss: 0.5401 - val_binary_accuracy: 0.3600 - val_loss: 0.7606\n",
            "Epoch 102/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6845 - loss: 0.5427 - val_binary_accuracy: 0.3600 - val_loss: 0.7765\n",
            "Epoch 103/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6874 - loss: 0.5395 - val_binary_accuracy: 0.3600 - val_loss: 0.7589\n",
            "Epoch 104/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6844 - loss: 0.5471 - val_binary_accuracy: 0.3600 - val_loss: 0.7898\n",
            "Epoch 105/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6550 - loss: 0.5602 - val_binary_accuracy: 0.3600 - val_loss: 0.7979\n",
            "Epoch 106/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7195 - loss: 0.5225 - val_binary_accuracy: 0.3600 - val_loss: 0.7735\n",
            "Epoch 107/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6991 - loss: 0.5363 - val_binary_accuracy: 0.3400 - val_loss: 0.7533\n",
            "Epoch 108/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7079 - loss: 0.5497 - val_binary_accuracy: 0.3400 - val_loss: 0.7684\n",
            "Epoch 109/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6940 - loss: 0.5467 - val_binary_accuracy: 0.3600 - val_loss: 0.7637\n",
            "Epoch 110/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6928 - loss: 0.5334 - val_binary_accuracy: 0.3400 - val_loss: 0.7637\n",
            "Epoch 111/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6772 - loss: 0.5441 - val_binary_accuracy: 0.3400 - val_loss: 0.7367\n",
            "Epoch 112/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6874 - loss: 0.5376 - val_binary_accuracy: 0.3600 - val_loss: 0.7724\n",
            "Epoch 113/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6668 - loss: 0.5522 - val_binary_accuracy: 0.3600 - val_loss: 0.7710\n",
            "Epoch 114/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6582 - loss: 0.5447 - val_binary_accuracy: 0.3600 - val_loss: 0.7940\n",
            "Epoch 115/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6920 - loss: 0.5389 - val_binary_accuracy: 0.3600 - val_loss: 0.7604\n",
            "Epoch 116/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6652 - loss: 0.5607 - val_binary_accuracy: 0.3600 - val_loss: 0.7987\n",
            "Epoch 117/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7089 - loss: 0.5072 - val_binary_accuracy: 0.3400 - val_loss: 0.7489\n",
            "Epoch 118/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6961 - loss: 0.5215 - val_binary_accuracy: 0.3600 - val_loss: 0.7748\n",
            "Epoch 119/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6931 - loss: 0.5297 - val_binary_accuracy: 0.3800 - val_loss: 0.7348\n",
            "Epoch 120/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6827 - loss: 0.5467 - val_binary_accuracy: 0.3600 - val_loss: 0.7533\n",
            "Epoch 121/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7226 - loss: 0.5128 - val_binary_accuracy: 0.3600 - val_loss: 0.7487\n",
            "Epoch 122/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6931 - loss: 0.5379 - val_binary_accuracy: 0.3800 - val_loss: 0.7978\n",
            "Epoch 123/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7079 - loss: 0.5337 - val_binary_accuracy: 0.3600 - val_loss: 0.7920\n",
            "Epoch 124/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7065 - loss: 0.5177 - val_binary_accuracy: 0.3600 - val_loss: 0.7714\n",
            "Epoch 125/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7161 - loss: 0.5262 - val_binary_accuracy: 0.3600 - val_loss: 0.7737\n",
            "Epoch 126/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7031 - loss: 0.5267 - val_binary_accuracy: 0.3600 - val_loss: 0.7629\n",
            "Epoch 127/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7324 - loss: 0.5067 - val_binary_accuracy: 0.3600 - val_loss: 0.7761\n",
            "Epoch 128/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7007 - loss: 0.5197 - val_binary_accuracy: 0.3600 - val_loss: 0.7500\n",
            "Epoch 129/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7486 - loss: 0.5021 - val_binary_accuracy: 0.3800 - val_loss: 0.7433\n",
            "Epoch 130/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6970 - loss: 0.5383 - val_binary_accuracy: 0.3800 - val_loss: 0.7964\n",
            "Epoch 131/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7129 - loss: 0.5165 - val_binary_accuracy: 0.3800 - val_loss: 0.8008\n",
            "Epoch 132/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6994 - loss: 0.5367 - val_binary_accuracy: 0.3600 - val_loss: 0.7883\n",
            "Epoch 133/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6882 - loss: 0.5289 - val_binary_accuracy: 0.3600 - val_loss: 0.7679\n",
            "Epoch 134/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7378 - loss: 0.4987 - val_binary_accuracy: 0.3600 - val_loss: 0.7499\n",
            "Epoch 135/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7374 - loss: 0.5232 - val_binary_accuracy: 0.3600 - val_loss: 0.7713\n",
            "Epoch 136/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7242 - loss: 0.5130 - val_binary_accuracy: 0.3600 - val_loss: 0.7624\n",
            "Epoch 137/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7531 - loss: 0.4920 - val_binary_accuracy: 0.3800 - val_loss: 0.7560\n",
            "Epoch 138/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7215 - loss: 0.5153 - val_binary_accuracy: 0.3600 - val_loss: 0.7870\n",
            "Epoch 139/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7170 - loss: 0.4963 - val_binary_accuracy: 0.3600 - val_loss: 0.7625\n",
            "Epoch 140/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7271 - loss: 0.5064 - val_binary_accuracy: 0.4200 - val_loss: 0.7280\n",
            "Epoch 141/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7575 - loss: 0.5266 - val_binary_accuracy: 0.3600 - val_loss: 0.7824\n",
            "Epoch 142/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7431 - loss: 0.4858 - val_binary_accuracy: 0.3800 - val_loss: 0.7516\n",
            "Epoch 143/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7233 - loss: 0.5253 - val_binary_accuracy: 0.3800 - val_loss: 0.7679\n",
            "Epoch 144/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7054 - loss: 0.5201 - val_binary_accuracy: 0.3600 - val_loss: 0.7701\n",
            "Epoch 145/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7163 - loss: 0.5081 - val_binary_accuracy: 0.3800 - val_loss: 0.7468\n",
            "Epoch 146/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7058 - loss: 0.5282 - val_binary_accuracy: 0.3800 - val_loss: 0.7853\n",
            "Epoch 147/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7493 - loss: 0.4876 - val_binary_accuracy: 0.3800 - val_loss: 0.7443\n",
            "Epoch 148/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7297 - loss: 0.5184 - val_binary_accuracy: 0.4000 - val_loss: 0.7639\n",
            "Epoch 149/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7371 - loss: 0.5052 - val_binary_accuracy: 0.3800 - val_loss: 0.7492\n",
            "Epoch 150/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7640 - loss: 0.4873 - val_binary_accuracy: 0.3800 - val_loss: 0.7579\n",
            "Epoch 151/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7469 - loss: 0.4897 - val_binary_accuracy: 0.3800 - val_loss: 0.7862\n",
            "Epoch 152/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7400 - loss: 0.4852 - val_binary_accuracy: 0.3800 - val_loss: 0.7514\n",
            "Epoch 153/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7300 - loss: 0.5141 - val_binary_accuracy: 0.3800 - val_loss: 0.7571\n",
            "Epoch 154/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7125 - loss: 0.4862 - val_binary_accuracy: 0.4000 - val_loss: 0.7285\n",
            "Epoch 155/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7726 - loss: 0.4824 - val_binary_accuracy: 0.4000 - val_loss: 0.7406\n",
            "Epoch 156/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7428 - loss: 0.5079 - val_binary_accuracy: 0.4000 - val_loss: 0.7768\n",
            "Epoch 157/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7276 - loss: 0.4854 - val_binary_accuracy: 0.4200 - val_loss: 0.7265\n",
            "Epoch 158/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7339 - loss: 0.4895 - val_binary_accuracy: 0.4000 - val_loss: 0.7635\n",
            "Epoch 159/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7403 - loss: 0.5016 - val_binary_accuracy: 0.4000 - val_loss: 0.7318\n",
            "Epoch 160/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7603 - loss: 0.4735 - val_binary_accuracy: 0.4000 - val_loss: 0.7634\n",
            "Epoch 161/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7241 - loss: 0.5132 - val_binary_accuracy: 0.4000 - val_loss: 0.7643\n",
            "Epoch 162/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7465 - loss: 0.4825 - val_binary_accuracy: 0.4000 - val_loss: 0.7562\n",
            "Epoch 163/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7502 - loss: 0.4815 - val_binary_accuracy: 0.4000 - val_loss: 0.7689\n",
            "Epoch 164/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7340 - loss: 0.4899 - val_binary_accuracy: 0.4000 - val_loss: 0.7529\n",
            "Epoch 165/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7184 - loss: 0.4923 - val_binary_accuracy: 0.4200 - val_loss: 0.7849\n",
            "Epoch 166/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7400 - loss: 0.4855 - val_binary_accuracy: 0.4200 - val_loss: 0.7472\n",
            "Epoch 167/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7195 - loss: 0.5033 - val_binary_accuracy: 0.4000 - val_loss: 0.7676\n",
            "Epoch 168/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7262 - loss: 0.4873 - val_binary_accuracy: 0.4200 - val_loss: 0.7480\n",
            "Epoch 169/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7167 - loss: 0.5096 - val_binary_accuracy: 0.4200 - val_loss: 0.7409\n",
            "Epoch 170/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7583 - loss: 0.4788 - val_binary_accuracy: 0.4600 - val_loss: 0.7438\n",
            "Epoch 171/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7203 - loss: 0.4854 - val_binary_accuracy: 0.4000 - val_loss: 0.7837\n",
            "Epoch 172/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7466 - loss: 0.4635 - val_binary_accuracy: 0.4200 - val_loss: 0.7501\n",
            "Epoch 173/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7544 - loss: 0.4756 - val_binary_accuracy: 0.4400 - val_loss: 0.7530\n",
            "Epoch 174/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7420 - loss: 0.4827 - val_binary_accuracy: 0.4400 - val_loss: 0.7575\n",
            "Epoch 175/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7364 - loss: 0.4730 - val_binary_accuracy: 0.4400 - val_loss: 0.7608\n",
            "Epoch 176/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7504 - loss: 0.4688 - val_binary_accuracy: 0.4600 - val_loss: 0.7305\n",
            "Epoch 177/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7449 - loss: 0.4928 - val_binary_accuracy: 0.4800 - val_loss: 0.7342\n",
            "Epoch 178/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.7033 - loss: 0.5041 - val_binary_accuracy: 0.4400 - val_loss: 0.7614\n",
            "Epoch 179/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7235 - loss: 0.4876 - val_binary_accuracy: 0.5200 - val_loss: 0.6910\n",
            "Epoch 180/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7543 - loss: 0.4736 - val_binary_accuracy: 0.4400 - val_loss: 0.7455\n",
            "Epoch 181/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7177 - loss: 0.4825 - val_binary_accuracy: 0.4200 - val_loss: 0.7806\n",
            "Epoch 182/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7348 - loss: 0.4774 - val_binary_accuracy: 0.4800 - val_loss: 0.7365\n",
            "Epoch 183/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7907 - loss: 0.4502 - val_binary_accuracy: 0.5200 - val_loss: 0.7159\n",
            "Epoch 184/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.7864 - loss: 0.4587 - val_binary_accuracy: 0.4800 - val_loss: 0.7423\n",
            "Epoch 185/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7425 - loss: 0.4695 - val_binary_accuracy: 0.4600 - val_loss: 0.7447\n",
            "Epoch 186/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7450 - loss: 0.4764 - val_binary_accuracy: 0.5600 - val_loss: 0.7201\n",
            "Epoch 187/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7407 - loss: 0.4623 - val_binary_accuracy: 0.5400 - val_loss: 0.7242\n",
            "Epoch 188/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7238 - loss: 0.4799 - val_binary_accuracy: 0.5000 - val_loss: 0.7335\n",
            "Epoch 189/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7483 - loss: 0.4578 - val_binary_accuracy: 0.4200 - val_loss: 0.7828\n",
            "Epoch 190/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7051 - loss: 0.5063 - val_binary_accuracy: 0.4200 - val_loss: 0.8167\n",
            "Epoch 191/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7427 - loss: 0.4775 - val_binary_accuracy: 0.5600 - val_loss: 0.7085\n",
            "Epoch 192/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7730 - loss: 0.4691 - val_binary_accuracy: 0.4600 - val_loss: 0.7471\n",
            "Epoch 193/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7314 - loss: 0.4759 - val_binary_accuracy: 0.4800 - val_loss: 0.7390\n",
            "Epoch 194/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7125 - loss: 0.4712 - val_binary_accuracy: 0.4600 - val_loss: 0.7665\n",
            "Epoch 195/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7119 - loss: 0.4837 - val_binary_accuracy: 0.5200 - val_loss: 0.7272\n",
            "Epoch 196/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7705 - loss: 0.4475 - val_binary_accuracy: 0.4600 - val_loss: 0.7503\n",
            "Epoch 197/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7635 - loss: 0.4624 - val_binary_accuracy: 0.4800 - val_loss: 0.7448\n",
            "Epoch 198/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7576 - loss: 0.4550 - val_binary_accuracy: 0.4600 - val_loss: 0.7508\n",
            "Epoch 199/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7604 - loss: 0.4550 - val_binary_accuracy: 0.5200 - val_loss: 0.7228\n",
            "Epoch 200/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7695 - loss: 0.4504 - val_binary_accuracy: 0.5400 - val_loss: 0.7189\n",
            "Epoch 201/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7562 - loss: 0.4649 - val_binary_accuracy: 0.5400 - val_loss: 0.7257\n",
            "Epoch 202/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7672 - loss: 0.4476 - val_binary_accuracy: 0.4600 - val_loss: 0.7764\n",
            "Epoch 203/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7196 - loss: 0.4615 - val_binary_accuracy: 0.5000 - val_loss: 0.7386\n",
            "Epoch 204/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7566 - loss: 0.4437 - val_binary_accuracy: 0.5000 - val_loss: 0.7436\n",
            "Epoch 205/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7548 - loss: 0.4636 - val_binary_accuracy: 0.4600 - val_loss: 0.7574\n",
            "Epoch 206/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7254 - loss: 0.4743 - val_binary_accuracy: 0.4600 - val_loss: 0.7566\n",
            "Epoch 207/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7462 - loss: 0.4555 - val_binary_accuracy: 0.5800 - val_loss: 0.7209\n",
            "Epoch 208/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7982 - loss: 0.4456 - val_binary_accuracy: 0.5800 - val_loss: 0.7277\n",
            "Epoch 209/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7640 - loss: 0.4661 - val_binary_accuracy: 0.5200 - val_loss: 0.7263\n",
            "Epoch 210/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7402 - loss: 0.4841 - val_binary_accuracy: 0.5200 - val_loss: 0.7373\n",
            "Epoch 211/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7523 - loss: 0.4587 - val_binary_accuracy: 0.5400 - val_loss: 0.7272\n",
            "Epoch 212/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7612 - loss: 0.4792 - val_binary_accuracy: 0.6000 - val_loss: 0.7072\n",
            "Epoch 213/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8205 - loss: 0.3991 - val_binary_accuracy: 0.5800 - val_loss: 0.6963\n",
            "Epoch 214/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7888 - loss: 0.4661 - val_binary_accuracy: 0.5200 - val_loss: 0.7452\n",
            "Epoch 215/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7729 - loss: 0.4439 - val_binary_accuracy: 0.5600 - val_loss: 0.7229\n",
            "Epoch 216/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7909 - loss: 0.4346 - val_binary_accuracy: 0.6000 - val_loss: 0.7122\n",
            "Epoch 217/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8015 - loss: 0.4553 - val_binary_accuracy: 0.5800 - val_loss: 0.6945\n",
            "Epoch 218/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8021 - loss: 0.4330 - val_binary_accuracy: 0.6200 - val_loss: 0.6821\n",
            "Epoch 219/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8187 - loss: 0.4357 - val_binary_accuracy: 0.6000 - val_loss: 0.7167\n",
            "Epoch 220/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8018 - loss: 0.4592 - val_binary_accuracy: 0.5800 - val_loss: 0.7302\n",
            "Epoch 221/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7750 - loss: 0.4509 - val_binary_accuracy: 0.5800 - val_loss: 0.6991\n",
            "Epoch 222/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7876 - loss: 0.4515 - val_binary_accuracy: 0.5200 - val_loss: 0.7481\n",
            "Epoch 223/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7599 - loss: 0.4439 - val_binary_accuracy: 0.5600 - val_loss: 0.7394\n",
            "Epoch 224/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7610 - loss: 0.4632 - val_binary_accuracy: 0.5600 - val_loss: 0.7214\n",
            "Epoch 225/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7754 - loss: 0.4503 - val_binary_accuracy: 0.5800 - val_loss: 0.7210\n",
            "Epoch 226/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8052 - loss: 0.4348 - val_binary_accuracy: 0.5800 - val_loss: 0.7197\n",
            "Epoch 227/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8136 - loss: 0.4475 - val_binary_accuracy: 0.6000 - val_loss: 0.7132\n",
            "Epoch 228/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7809 - loss: 0.4467 - val_binary_accuracy: 0.5600 - val_loss: 0.7340\n",
            "Epoch 229/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7604 - loss: 0.4578 - val_binary_accuracy: 0.5200 - val_loss: 0.7552\n",
            "Epoch 230/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7548 - loss: 0.4345 - val_binary_accuracy: 0.6000 - val_loss: 0.7172\n",
            "Epoch 231/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8080 - loss: 0.4277 - val_binary_accuracy: 0.5600 - val_loss: 0.7347\n",
            "Epoch 232/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7751 - loss: 0.4347 - val_binary_accuracy: 0.5600 - val_loss: 0.7401\n",
            "Epoch 233/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7548 - loss: 0.4385 - val_binary_accuracy: 0.6000 - val_loss: 0.7026\n",
            "Epoch 234/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7997 - loss: 0.4367 - val_binary_accuracy: 0.5800 - val_loss: 0.7240\n",
            "Epoch 235/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8177 - loss: 0.4181 - val_binary_accuracy: 0.6000 - val_loss: 0.7043\n",
            "Epoch 236/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8168 - loss: 0.4302 - val_binary_accuracy: 0.6400 - val_loss: 0.6776\n",
            "Epoch 237/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8051 - loss: 0.4392 - val_binary_accuracy: 0.6400 - val_loss: 0.7045\n",
            "Epoch 238/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7939 - loss: 0.4383 - val_binary_accuracy: 0.6000 - val_loss: 0.7184\n",
            "Epoch 239/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7959 - loss: 0.4411 - val_binary_accuracy: 0.5800 - val_loss: 0.7308\n",
            "Epoch 240/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7924 - loss: 0.4504 - val_binary_accuracy: 0.6000 - val_loss: 0.7110\n",
            "Epoch 241/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8026 - loss: 0.4160 - val_binary_accuracy: 0.5800 - val_loss: 0.7160\n",
            "Epoch 242/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8078 - loss: 0.4326 - val_binary_accuracy: 0.6200 - val_loss: 0.7189\n",
            "Epoch 243/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8032 - loss: 0.4212 - val_binary_accuracy: 0.5800 - val_loss: 0.7204\n",
            "Epoch 244/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8002 - loss: 0.4128 - val_binary_accuracy: 0.6400 - val_loss: 0.6811\n",
            "Epoch 245/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8326 - loss: 0.4222 - val_binary_accuracy: 0.6000 - val_loss: 0.7035\n",
            "Epoch 246/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8341 - loss: 0.4278 - val_binary_accuracy: 0.6400 - val_loss: 0.6869\n",
            "Epoch 247/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8082 - loss: 0.4392 - val_binary_accuracy: 0.5800 - val_loss: 0.7420\n",
            "Epoch 248/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7849 - loss: 0.4326 - val_binary_accuracy: 0.6200 - val_loss: 0.7170\n",
            "Epoch 249/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8055 - loss: 0.4181 - val_binary_accuracy: 0.6400 - val_loss: 0.6839\n",
            "Epoch 250/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8078 - loss: 0.4186 - val_binary_accuracy: 0.6000 - val_loss: 0.7080\n",
            "Epoch 251/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8090 - loss: 0.4386 - val_binary_accuracy: 0.6200 - val_loss: 0.7250\n",
            "Epoch 252/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7874 - loss: 0.4203 - val_binary_accuracy: 0.6400 - val_loss: 0.6718\n",
            "Epoch 253/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8369 - loss: 0.4289 - val_binary_accuracy: 0.6200 - val_loss: 0.7174\n",
            "Epoch 254/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7810 - loss: 0.4177 - val_binary_accuracy: 0.6000 - val_loss: 0.7019\n",
            "Epoch 255/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8158 - loss: 0.4132 - val_binary_accuracy: 0.6400 - val_loss: 0.7134\n",
            "Epoch 256/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7846 - loss: 0.4143 - val_binary_accuracy: 0.6200 - val_loss: 0.6948\n",
            "Epoch 257/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8438 - loss: 0.3955 - val_binary_accuracy: 0.5600 - val_loss: 0.7471\n",
            "Epoch 258/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7641 - loss: 0.4365 - val_binary_accuracy: 0.6000 - val_loss: 0.7268\n",
            "Epoch 259/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7991 - loss: 0.4047 - val_binary_accuracy: 0.6200 - val_loss: 0.7035\n",
            "Epoch 260/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8183 - loss: 0.4183 - val_binary_accuracy: 0.6000 - val_loss: 0.7363\n",
            "Epoch 261/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8168 - loss: 0.3954 - val_binary_accuracy: 0.5800 - val_loss: 0.7222\n",
            "Epoch 262/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7891 - loss: 0.4162 - val_binary_accuracy: 0.6400 - val_loss: 0.6971\n",
            "Epoch 263/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8212 - loss: 0.4173 - val_binary_accuracy: 0.5800 - val_loss: 0.7390\n",
            "Epoch 264/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7583 - loss: 0.4257 - val_binary_accuracy: 0.6200 - val_loss: 0.6956\n",
            "Epoch 265/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8442 - loss: 0.4147 - val_binary_accuracy: 0.6000 - val_loss: 0.7297\n",
            "Epoch 266/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8130 - loss: 0.3953 - val_binary_accuracy: 0.6400 - val_loss: 0.7032\n",
            "Epoch 267/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7900 - loss: 0.4143 - val_binary_accuracy: 0.6200 - val_loss: 0.6856\n",
            "Epoch 268/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8561 - loss: 0.4135 - val_binary_accuracy: 0.6000 - val_loss: 0.7323\n",
            "Epoch 269/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8032 - loss: 0.4278 - val_binary_accuracy: 0.6200 - val_loss: 0.7234\n",
            "Epoch 270/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8058 - loss: 0.4249 - val_binary_accuracy: 0.6600 - val_loss: 0.6867\n",
            "Epoch 271/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8320 - loss: 0.4079 - val_binary_accuracy: 0.6000 - val_loss: 0.7202\n",
            "Epoch 272/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8028 - loss: 0.4157 - val_binary_accuracy: 0.6400 - val_loss: 0.6924\n",
            "Epoch 273/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8208 - loss: 0.3986 - val_binary_accuracy: 0.6400 - val_loss: 0.6617\n",
            "Epoch 274/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8643 - loss: 0.4076 - val_binary_accuracy: 0.6400 - val_loss: 0.6885\n",
            "Epoch 275/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8186 - loss: 0.4212 - val_binary_accuracy: 0.6000 - val_loss: 0.7261\n",
            "Epoch 276/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8052 - loss: 0.3987 - val_binary_accuracy: 0.6400 - val_loss: 0.6883\n",
            "Epoch 277/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8115 - loss: 0.4134 - val_binary_accuracy: 0.6400 - val_loss: 0.7056\n",
            "Epoch 278/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8344 - loss: 0.3932 - val_binary_accuracy: 0.6400 - val_loss: 0.7057\n",
            "Epoch 279/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8240 - loss: 0.4058 - val_binary_accuracy: 0.6400 - val_loss: 0.6964\n",
            "Epoch 280/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7970 - loss: 0.4076 - val_binary_accuracy: 0.6400 - val_loss: 0.7060\n",
            "Epoch 281/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8036 - loss: 0.3960 - val_binary_accuracy: 0.6400 - val_loss: 0.7055\n",
            "Epoch 282/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8147 - loss: 0.3999 - val_binary_accuracy: 0.6400 - val_loss: 0.7092\n",
            "Epoch 283/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8369 - loss: 0.3958 - val_binary_accuracy: 0.6400 - val_loss: 0.6592\n",
            "Epoch 284/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.8500 - loss: 0.4081 - val_binary_accuracy: 0.6400 - val_loss: 0.7183\n",
            "Epoch 285/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8433 - loss: 0.4152 - val_binary_accuracy: 0.6000 - val_loss: 0.7550\n",
            "Epoch 286/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7861 - loss: 0.4136 - val_binary_accuracy: 0.6400 - val_loss: 0.7087\n",
            "Epoch 287/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8566 - loss: 0.3667 - val_binary_accuracy: 0.6400 - val_loss: 0.6718\n",
            "Epoch 288/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.8699 - loss: 0.3845 - val_binary_accuracy: 0.6400 - val_loss: 0.7061\n",
            "Epoch 289/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8032 - loss: 0.3871 - val_binary_accuracy: 0.6400 - val_loss: 0.6714\n",
            "Epoch 290/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.8424 - loss: 0.4248 - val_binary_accuracy: 0.6200 - val_loss: 0.6995\n",
            "Epoch 291/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.8251 - loss: 0.4007 - val_binary_accuracy: 0.6400 - val_loss: 0.7221\n",
            "Epoch 292/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8119 - loss: 0.4100 - val_binary_accuracy: 0.6400 - val_loss: 0.7181\n",
            "Epoch 293/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8152 - loss: 0.4024 - val_binary_accuracy: 0.5000 - val_loss: 0.7886\n",
            "Epoch 294/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7854 - loss: 0.3799 - val_binary_accuracy: 0.6600 - val_loss: 0.6886\n",
            "Epoch 295/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8492 - loss: 0.3861 - val_binary_accuracy: 0.6400 - val_loss: 0.6739\n",
            "Epoch 296/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.8558 - loss: 0.3946 - val_binary_accuracy: 0.6200 - val_loss: 0.7294\n",
            "Epoch 297/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8362 - loss: 0.3851 - val_binary_accuracy: 0.6400 - val_loss: 0.7108\n",
            "Epoch 298/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8433 - loss: 0.4038 - val_binary_accuracy: 0.6400 - val_loss: 0.7276\n",
            "Epoch 299/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.8200 - loss: 0.3921 - val_binary_accuracy: 0.5800 - val_loss: 0.7557\n",
            "Epoch 300/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - binary_accuracy: 0.7797 - loss: 0.4049 - val_binary_accuracy: 0.6600 - val_loss: 0.6750\n",
            "Epoch 301/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8653 - loss: 0.3812 - val_binary_accuracy: 0.6400 - val_loss: 0.7149\n",
            "Epoch 302/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8427 - loss: 0.3916 - val_binary_accuracy: 0.6400 - val_loss: 0.7075\n",
            "Epoch 303/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8488 - loss: 0.3777 - val_binary_accuracy: 0.6200 - val_loss: 0.7260\n",
            "Epoch 304/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8010 - loss: 0.4080 - val_binary_accuracy: 0.6600 - val_loss: 0.6755\n",
            "Epoch 305/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8662 - loss: 0.3717 - val_binary_accuracy: 0.6400 - val_loss: 0.6975\n",
            "Epoch 306/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8753 - loss: 0.3793 - val_binary_accuracy: 0.6600 - val_loss: 0.7035\n",
            "Epoch 307/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8451 - loss: 0.3752 - val_binary_accuracy: 0.6600 - val_loss: 0.7002\n",
            "Epoch 308/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8656 - loss: 0.3783 - val_binary_accuracy: 0.6600 - val_loss: 0.7023\n",
            "Epoch 309/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8575 - loss: 0.3762 - val_binary_accuracy: 0.6200 - val_loss: 0.7322\n",
            "Epoch 310/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8078 - loss: 0.3673 - val_binary_accuracy: 0.6600 - val_loss: 0.6820\n",
            "Epoch 311/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8521 - loss: 0.3876 - val_binary_accuracy: 0.6400 - val_loss: 0.6956\n",
            "Epoch 312/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8463 - loss: 0.3750 - val_binary_accuracy: 0.6400 - val_loss: 0.6908\n",
            "Epoch 313/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8908 - loss: 0.3671 - val_binary_accuracy: 0.6400 - val_loss: 0.6708\n",
            "Epoch 314/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.8798 - loss: 0.3704 - val_binary_accuracy: 0.6600 - val_loss: 0.7105\n",
            "Epoch 315/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8507 - loss: 0.3601 - val_binary_accuracy: 0.6600 - val_loss: 0.7071\n",
            "Epoch 316/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8586 - loss: 0.3820 - val_binary_accuracy: 0.6400 - val_loss: 0.7147\n",
            "Epoch 317/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8377 - loss: 0.3795 - val_binary_accuracy: 0.6200 - val_loss: 0.7189\n",
            "Epoch 318/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8447 - loss: 0.3835 - val_binary_accuracy: 0.6400 - val_loss: 0.6934\n",
            "Epoch 319/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8661 - loss: 0.3802 - val_binary_accuracy: 0.6600 - val_loss: 0.6861\n",
            "Epoch 320/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8668 - loss: 0.3694 - val_binary_accuracy: 0.6600 - val_loss: 0.7144\n",
            "Epoch 321/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8908 - loss: 0.3634 - val_binary_accuracy: 0.6400 - val_loss: 0.6939\n",
            "Epoch 322/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8852 - loss: 0.3518 - val_binary_accuracy: 0.6200 - val_loss: 0.7290\n",
            "Epoch 323/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8633 - loss: 0.3619 - val_binary_accuracy: 0.6600 - val_loss: 0.7241\n",
            "Epoch 324/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8454 - loss: 0.3531 - val_binary_accuracy: 0.6600 - val_loss: 0.6903\n",
            "Epoch 325/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8736 - loss: 0.3592 - val_binary_accuracy: 0.6200 - val_loss: 0.7193\n",
            "Epoch 326/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8481 - loss: 0.3908 - val_binary_accuracy: 0.6400 - val_loss: 0.6652\n",
            "Epoch 327/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8992 - loss: 0.3720 - val_binary_accuracy: 0.6600 - val_loss: 0.6919\n",
            "Epoch 328/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8620 - loss: 0.3950 - val_binary_accuracy: 0.6200 - val_loss: 0.7373\n",
            "Epoch 329/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8248 - loss: 0.3813 - val_binary_accuracy: 0.6200 - val_loss: 0.7340\n",
            "Epoch 330/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8073 - loss: 0.3716 - val_binary_accuracy: 0.6400 - val_loss: 0.6747\n",
            "Epoch 331/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8583 - loss: 0.3779 - val_binary_accuracy: 0.6400 - val_loss: 0.6788\n",
            "Epoch 332/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8967 - loss: 0.3724 - val_binary_accuracy: 0.6400 - val_loss: 0.6802\n",
            "Epoch 333/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8697 - loss: 0.3702 - val_binary_accuracy: 0.6600 - val_loss: 0.7014\n",
            "Epoch 334/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9006 - loss: 0.3558 - val_binary_accuracy: 0.6400 - val_loss: 0.6759\n",
            "Epoch 335/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8597 - loss: 0.3573 - val_binary_accuracy: 0.6600 - val_loss: 0.6814\n",
            "Epoch 336/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8636 - loss: 0.3724 - val_binary_accuracy: 0.6600 - val_loss: 0.7121\n",
            "Epoch 337/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8570 - loss: 0.3724 - val_binary_accuracy: 0.6600 - val_loss: 0.7114\n",
            "Epoch 338/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8424 - loss: 0.3701 - val_binary_accuracy: 0.6600 - val_loss: 0.6794\n",
            "Epoch 339/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8798 - loss: 0.3505 - val_binary_accuracy: 0.6400 - val_loss: 0.6920\n",
            "Epoch 340/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8818 - loss: 0.3496 - val_binary_accuracy: 0.6400 - val_loss: 0.6680\n",
            "Epoch 341/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9010 - loss: 0.3800 - val_binary_accuracy: 0.6200 - val_loss: 0.7226\n",
            "Epoch 342/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8643 - loss: 0.3609 - val_binary_accuracy: 0.6600 - val_loss: 0.7123\n",
            "Epoch 343/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8502 - loss: 0.3725 - val_binary_accuracy: 0.6600 - val_loss: 0.7076\n",
            "Epoch 344/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8761 - loss: 0.3471 - val_binary_accuracy: 0.6600 - val_loss: 0.7132\n",
            "Epoch 345/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8397 - loss: 0.3709 - val_binary_accuracy: 0.6600 - val_loss: 0.7014\n",
            "Epoch 346/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9013 - loss: 0.3636 - val_binary_accuracy: 0.6600 - val_loss: 0.6529\n",
            "Epoch 347/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8925 - loss: 0.3585 - val_binary_accuracy: 0.6600 - val_loss: 0.6893\n",
            "Epoch 348/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8723 - loss: 0.3907 - val_binary_accuracy: 0.6400 - val_loss: 0.6693\n",
            "Epoch 349/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8893 - loss: 0.3678 - val_binary_accuracy: 0.6600 - val_loss: 0.6988\n",
            "Epoch 350/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9046 - loss: 0.3280 - val_binary_accuracy: 0.6200 - val_loss: 0.7314\n",
            "Epoch 351/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8387 - loss: 0.3721 - val_binary_accuracy: 0.6600 - val_loss: 0.6948\n",
            "Epoch 352/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9004 - loss: 0.3487 - val_binary_accuracy: 0.6400 - val_loss: 0.6790\n",
            "Epoch 353/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9070 - loss: 0.3721 - val_binary_accuracy: 0.6600 - val_loss: 0.6980\n",
            "Epoch 354/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8986 - loss: 0.3440 - val_binary_accuracy: 0.6400 - val_loss: 0.6758\n",
            "Epoch 355/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8764 - loss: 0.3610 - val_binary_accuracy: 0.6600 - val_loss: 0.7189\n",
            "Epoch 356/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9006 - loss: 0.3351 - val_binary_accuracy: 0.6600 - val_loss: 0.7035\n",
            "Epoch 357/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8814 - loss: 0.3509 - val_binary_accuracy: 0.6600 - val_loss: 0.7058\n",
            "Epoch 358/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8620 - loss: 0.3510 - val_binary_accuracy: 0.6400 - val_loss: 0.7410\n",
            "Epoch 359/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8351 - loss: 0.3682 - val_binary_accuracy: 0.6600 - val_loss: 0.6920\n",
            "Epoch 360/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8512 - loss: 0.3709 - val_binary_accuracy: 0.6400 - val_loss: 0.7360\n",
            "Epoch 361/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8575 - loss: 0.3542 - val_binary_accuracy: 0.6600 - val_loss: 0.7035\n",
            "Epoch 362/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9046 - loss: 0.3372 - val_binary_accuracy: 0.6400 - val_loss: 0.7167\n",
            "Epoch 363/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8618 - loss: 0.3555 - val_binary_accuracy: 0.6600 - val_loss: 0.6898\n",
            "Epoch 364/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8771 - loss: 0.3462 - val_binary_accuracy: 0.6600 - val_loss: 0.6938\n",
            "Epoch 365/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8802 - loss: 0.3520 - val_binary_accuracy: 0.6400 - val_loss: 0.6704\n",
            "Epoch 366/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9030 - loss: 0.3314 - val_binary_accuracy: 0.6600 - val_loss: 0.6841\n",
            "Epoch 367/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8980 - loss: 0.3277 - val_binary_accuracy: 0.6600 - val_loss: 0.7149\n",
            "Epoch 368/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8902 - loss: 0.3447 - val_binary_accuracy: 0.6600 - val_loss: 0.7040\n",
            "Epoch 369/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8726 - loss: 0.3356 - val_binary_accuracy: 0.6600 - val_loss: 0.6511\n",
            "Epoch 370/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9057 - loss: 0.3407 - val_binary_accuracy: 0.6600 - val_loss: 0.6806\n",
            "Epoch 371/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8676 - loss: 0.3444 - val_binary_accuracy: 0.6600 - val_loss: 0.7076\n",
            "Epoch 372/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8810 - loss: 0.3438 - val_binary_accuracy: 0.6600 - val_loss: 0.7186\n",
            "Epoch 373/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8728 - loss: 0.3486 - val_binary_accuracy: 0.6400 - val_loss: 0.7498\n",
            "Epoch 374/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8455 - loss: 0.3420 - val_binary_accuracy: 0.6600 - val_loss: 0.7022\n",
            "Epoch 375/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8895 - loss: 0.3357 - val_binary_accuracy: 0.6600 - val_loss: 0.6940\n",
            "Epoch 376/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9017 - loss: 0.3582 - val_binary_accuracy: 0.6600 - val_loss: 0.7107\n",
            "Epoch 377/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8543 - loss: 0.3499 - val_binary_accuracy: 0.6400 - val_loss: 0.7748\n",
            "Epoch 378/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8480 - loss: 0.3319 - val_binary_accuracy: 0.6600 - val_loss: 0.7105\n",
            "Epoch 379/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8872 - loss: 0.3572 - val_binary_accuracy: 0.6400 - val_loss: 0.7545\n",
            "Epoch 380/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8833 - loss: 0.3427 - val_binary_accuracy: 0.6600 - val_loss: 0.7139\n",
            "Epoch 381/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9088 - loss: 0.3194 - val_binary_accuracy: 0.6400 - val_loss: 0.6777\n",
            "Epoch 382/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9056 - loss: 0.3191 - val_binary_accuracy: 0.6600 - val_loss: 0.7166\n",
            "Epoch 383/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.8828 - loss: 0.3271 - val_binary_accuracy: 0.6600 - val_loss: 0.7079\n",
            "Epoch 384/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.8836 - loss: 0.3352 - val_binary_accuracy: 0.6400 - val_loss: 0.6833\n",
            "Epoch 385/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.8842 - loss: 0.3337 - val_binary_accuracy: 0.6600 - val_loss: 0.7025\n",
            "Epoch 386/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.8976 - loss: 0.3261 - val_binary_accuracy: 0.6400 - val_loss: 0.6647\n",
            "Epoch 387/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9050 - loss: 0.3608 - val_binary_accuracy: 0.6400 - val_loss: 0.7518\n",
            "Epoch 388/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8691 - loss: 0.3307 - val_binary_accuracy: 0.6600 - val_loss: 0.7057\n",
            "Epoch 389/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8911 - loss: 0.3358 - val_binary_accuracy: 0.6400 - val_loss: 0.6694\n",
            "Epoch 390/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.8896 - loss: 0.3325 - val_binary_accuracy: 0.6600 - val_loss: 0.7022\n",
            "Epoch 391/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8912 - loss: 0.3408 - val_binary_accuracy: 0.6400 - val_loss: 0.6592\n",
            "Epoch 392/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.8987 - loss: 0.3243 - val_binary_accuracy: 0.6400 - val_loss: 0.6681\n",
            "Epoch 393/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.8986 - loss: 0.3111 - val_binary_accuracy: 0.6600 - val_loss: 0.6828\n",
            "Epoch 394/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9164 - loss: 0.3182 - val_binary_accuracy: 0.6600 - val_loss: 0.7163\n",
            "Epoch 395/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9169 - loss: 0.3057 - val_binary_accuracy: 0.6400 - val_loss: 0.6804\n",
            "Epoch 396/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9001 - loss: 0.3313 - val_binary_accuracy: 0.6600 - val_loss: 0.7174\n",
            "Epoch 397/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.8983 - loss: 0.3233 - val_binary_accuracy: 0.6600 - val_loss: 0.7146\n",
            "Epoch 398/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.8766 - loss: 0.3224 - val_binary_accuracy: 0.6400 - val_loss: 0.6609\n",
            "Epoch 399/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9009 - loss: 0.3272 - val_binary_accuracy: 0.6400 - val_loss: 0.6772\n",
            "Epoch 400/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8882 - loss: 0.3173 - val_binary_accuracy: 0.6400 - val_loss: 0.6667\n",
            "Epoch 401/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8846 - loss: 0.3427 - val_binary_accuracy: 0.6400 - val_loss: 0.6663\n",
            "Epoch 402/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8953 - loss: 0.3280 - val_binary_accuracy: 0.6600 - val_loss: 0.7748\n",
            "Epoch 403/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8439 - loss: 0.3581 - val_binary_accuracy: 0.6600 - val_loss: 0.7146\n",
            "Epoch 404/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8868 - loss: 0.3150 - val_binary_accuracy: 0.6600 - val_loss: 0.7055\n",
            "Epoch 405/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9096 - loss: 0.3080 - val_binary_accuracy: 0.6600 - val_loss: 0.7237\n",
            "Epoch 406/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8718 - loss: 0.3487 - val_binary_accuracy: 0.6400 - val_loss: 0.6971\n",
            "Epoch 407/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9143 - loss: 0.3139 - val_binary_accuracy: 0.6400 - val_loss: 0.6641\n",
            "Epoch 408/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9076 - loss: 0.3122 - val_binary_accuracy: 0.6400 - val_loss: 0.6808\n",
            "Epoch 409/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9035 - loss: 0.3174 - val_binary_accuracy: 0.6400 - val_loss: 0.6895\n",
            "Epoch 410/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8968 - loss: 0.3331 - val_binary_accuracy: 0.6400 - val_loss: 0.6727\n",
            "Epoch 411/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9204 - loss: 0.3111 - val_binary_accuracy: 0.6400 - val_loss: 0.6875\n",
            "Epoch 412/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8841 - loss: 0.3281 - val_binary_accuracy: 0.6600 - val_loss: 0.7377\n",
            "Epoch 413/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8657 - loss: 0.3404 - val_binary_accuracy: 0.6400 - val_loss: 0.6671\n",
            "Epoch 414/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8919 - loss: 0.3173 - val_binary_accuracy: 0.6600 - val_loss: 0.7230\n",
            "Epoch 415/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8981 - loss: 0.3397 - val_binary_accuracy: 0.6400 - val_loss: 0.6964\n",
            "Epoch 416/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9157 - loss: 0.3240 - val_binary_accuracy: 0.6400 - val_loss: 0.6789\n",
            "Epoch 417/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9007 - loss: 0.3268 - val_binary_accuracy: 0.6400 - val_loss: 0.6687\n",
            "Epoch 418/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9122 - loss: 0.3319 - val_binary_accuracy: 0.6400 - val_loss: 0.6875\n",
            "Epoch 419/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9328 - loss: 0.2897 - val_binary_accuracy: 0.6600 - val_loss: 0.7369\n",
            "Epoch 420/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8532 - loss: 0.3435 - val_binary_accuracy: 0.6400 - val_loss: 0.6758\n",
            "Epoch 421/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9192 - loss: 0.3141 - val_binary_accuracy: 0.6400 - val_loss: 0.6786\n",
            "Epoch 422/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9108 - loss: 0.3039 - val_binary_accuracy: 0.6400 - val_loss: 0.6892\n",
            "Epoch 423/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8893 - loss: 0.3074 - val_binary_accuracy: 0.6400 - val_loss: 0.6809\n",
            "Epoch 424/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8928 - loss: 0.3254 - val_binary_accuracy: 0.6400 - val_loss: 0.6793\n",
            "Epoch 425/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9122 - loss: 0.3190 - val_binary_accuracy: 0.6400 - val_loss: 0.6909\n",
            "Epoch 426/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9081 - loss: 0.3132 - val_binary_accuracy: 0.6400 - val_loss: 0.7018\n",
            "Epoch 427/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9060 - loss: 0.3216 - val_binary_accuracy: 0.6400 - val_loss: 0.6565\n",
            "Epoch 428/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9109 - loss: 0.3022 - val_binary_accuracy: 0.6400 - val_loss: 0.7381\n",
            "Epoch 429/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9056 - loss: 0.3044 - val_binary_accuracy: 0.6400 - val_loss: 0.6970\n",
            "Epoch 430/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9020 - loss: 0.3239 - val_binary_accuracy: 0.6600 - val_loss: 0.7013\n",
            "Epoch 431/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9161 - loss: 0.3027 - val_binary_accuracy: 0.6400 - val_loss: 0.6981\n",
            "Epoch 432/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9083 - loss: 0.2986 - val_binary_accuracy: 0.6400 - val_loss: 0.6929\n",
            "Epoch 433/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9174 - loss: 0.3041 - val_binary_accuracy: 0.6600 - val_loss: 0.6506\n",
            "Epoch 434/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9161 - loss: 0.3151 - val_binary_accuracy: 0.6200 - val_loss: 0.6872\n",
            "Epoch 435/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9043 - loss: 0.3189 - val_binary_accuracy: 0.6400 - val_loss: 0.7335\n",
            "Epoch 436/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8871 - loss: 0.3157 - val_binary_accuracy: 0.6200 - val_loss: 0.6909\n",
            "Epoch 437/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9199 - loss: 0.3154 - val_binary_accuracy: 0.6400 - val_loss: 0.7425\n",
            "Epoch 438/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9058 - loss: 0.2941 - val_binary_accuracy: 0.6400 - val_loss: 0.7066\n",
            "Epoch 439/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9028 - loss: 0.3131 - val_binary_accuracy: 0.6400 - val_loss: 0.6873\n",
            "Epoch 440/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9027 - loss: 0.2996 - val_binary_accuracy: 0.6600 - val_loss: 0.7007\n",
            "Epoch 441/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8678 - loss: 0.3155 - val_binary_accuracy: 0.6400 - val_loss: 0.6767\n",
            "Epoch 442/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.8877 - loss: 0.3213 - val_binary_accuracy: 0.6400 - val_loss: 0.6649\n",
            "Epoch 443/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9325 - loss: 0.2840 - val_binary_accuracy: 0.6400 - val_loss: 0.6546\n",
            "Epoch 444/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9014 - loss: 0.3051 - val_binary_accuracy: 0.6600 - val_loss: 0.7120\n",
            "Epoch 445/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8808 - loss: 0.3221 - val_binary_accuracy: 0.6400 - val_loss: 0.6676\n",
            "Epoch 446/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9109 - loss: 0.3102 - val_binary_accuracy: 0.6400 - val_loss: 0.6723\n",
            "Epoch 447/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9150 - loss: 0.3088 - val_binary_accuracy: 0.6400 - val_loss: 0.6965\n",
            "Epoch 448/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9236 - loss: 0.2810 - val_binary_accuracy: 0.6600 - val_loss: 0.7568\n",
            "Epoch 449/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8671 - loss: 0.3122 - val_binary_accuracy: 0.6600 - val_loss: 0.6524\n",
            "Epoch 450/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9093 - loss: 0.3180 - val_binary_accuracy: 0.6400 - val_loss: 0.6644\n",
            "Epoch 451/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9277 - loss: 0.2808 - val_binary_accuracy: 0.6600 - val_loss: 0.6423\n",
            "Epoch 452/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9381 - loss: 0.2857 - val_binary_accuracy: 0.6400 - val_loss: 0.7355\n",
            "Epoch 453/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8974 - loss: 0.2978 - val_binary_accuracy: 0.6600 - val_loss: 0.7063\n",
            "Epoch 454/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9164 - loss: 0.2931 - val_binary_accuracy: 0.6400 - val_loss: 0.7530\n",
            "Epoch 455/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8927 - loss: 0.2920 - val_binary_accuracy: 0.6600 - val_loss: 0.6545\n",
            "Epoch 456/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9240 - loss: 0.3092 - val_binary_accuracy: 0.6600 - val_loss: 0.7015\n",
            "Epoch 457/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9044 - loss: 0.3001 - val_binary_accuracy: 0.6600 - val_loss: 0.7172\n",
            "Epoch 458/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9016 - loss: 0.3057 - val_binary_accuracy: 0.6600 - val_loss: 0.7016\n",
            "Epoch 459/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9065 - loss: 0.2917 - val_binary_accuracy: 0.6400 - val_loss: 0.6818\n",
            "Epoch 460/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9414 - loss: 0.2817 - val_binary_accuracy: 0.6400 - val_loss: 0.6712\n",
            "Epoch 461/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9106 - loss: 0.2876 - val_binary_accuracy: 0.6200 - val_loss: 0.6935\n",
            "Epoch 462/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9066 - loss: 0.2849 - val_binary_accuracy: 0.6600 - val_loss: 0.7156\n",
            "Epoch 463/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8885 - loss: 0.3139 - val_binary_accuracy: 0.6400 - val_loss: 0.6876\n",
            "Epoch 464/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9046 - loss: 0.2973 - val_binary_accuracy: 0.6400 - val_loss: 0.6760\n",
            "Epoch 465/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9131 - loss: 0.2954 - val_binary_accuracy: 0.6200 - val_loss: 0.7012\n",
            "Epoch 466/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9145 - loss: 0.2981 - val_binary_accuracy: 0.6200 - val_loss: 0.6954\n",
            "Epoch 467/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9081 - loss: 0.2852 - val_binary_accuracy: 0.6600 - val_loss: 0.7168\n",
            "Epoch 468/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9192 - loss: 0.2782 - val_binary_accuracy: 0.6400 - val_loss: 0.6756\n",
            "Epoch 469/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9060 - loss: 0.3194 - val_binary_accuracy: 0.6600 - val_loss: 0.7115\n",
            "Epoch 470/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9164 - loss: 0.3025 - val_binary_accuracy: 0.6400 - val_loss: 0.6876\n",
            "Epoch 471/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9131 - loss: 0.2943 - val_binary_accuracy: 0.6200 - val_loss: 0.7088\n",
            "Epoch 472/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9083 - loss: 0.2775 - val_binary_accuracy: 0.6400 - val_loss: 0.6943\n",
            "Epoch 473/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9117 - loss: 0.2766 - val_binary_accuracy: 0.6200 - val_loss: 0.7000\n",
            "Epoch 474/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9322 - loss: 0.2654 - val_binary_accuracy: 0.6400 - val_loss: 0.6904\n",
            "Epoch 475/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9174 - loss: 0.2817 - val_binary_accuracy: 0.6400 - val_loss: 0.7019\n",
            "Epoch 476/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9242 - loss: 0.2835 - val_binary_accuracy: 0.6400 - val_loss: 0.7002\n",
            "Epoch 477/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8963 - loss: 0.2900 - val_binary_accuracy: 0.6600 - val_loss: 0.7385\n",
            "Epoch 478/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9154 - loss: 0.2992 - val_binary_accuracy: 0.6400 - val_loss: 0.6836\n",
            "Epoch 479/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9359 - loss: 0.2851 - val_binary_accuracy: 0.6400 - val_loss: 0.6666\n",
            "Epoch 480/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9316 - loss: 0.2889 - val_binary_accuracy: 0.6200 - val_loss: 0.7019\n",
            "Epoch 481/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9001 - loss: 0.2985 - val_binary_accuracy: 0.6400 - val_loss: 0.6878\n",
            "Epoch 482/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9283 - loss: 0.2735 - val_binary_accuracy: 0.6400 - val_loss: 0.6734\n",
            "Epoch 483/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9157 - loss: 0.2910 - val_binary_accuracy: 0.6600 - val_loss: 0.7242\n",
            "Epoch 484/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - binary_accuracy: 0.9122 - loss: 0.2846 - val_binary_accuracy: 0.6400 - val_loss: 0.6695\n",
            "Epoch 485/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9084 - loss: 0.2997 - val_binary_accuracy: 0.6400 - val_loss: 0.6997\n",
            "Epoch 486/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9443 - loss: 0.2716 - val_binary_accuracy: 0.6400 - val_loss: 0.6997\n",
            "Epoch 487/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9095 - loss: 0.2897 - val_binary_accuracy: 0.6400 - val_loss: 0.6974\n",
            "Epoch 488/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9206 - loss: 0.2759 - val_binary_accuracy: 0.6600 - val_loss: 0.6454\n",
            "Epoch 489/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - binary_accuracy: 0.9009 - loss: 0.2928 - val_binary_accuracy: 0.6600 - val_loss: 0.7223\n",
            "Epoch 490/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9238 - loss: 0.2752 - val_binary_accuracy: 0.6600 - val_loss: 0.7251\n",
            "Epoch 491/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9023 - loss: 0.3161 - val_binary_accuracy: 0.6200 - val_loss: 0.7127\n",
            "Epoch 492/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.9320 - loss: 0.2802 - val_binary_accuracy: 0.6400 - val_loss: 0.6986\n",
            "Epoch 493/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9529 - loss: 0.2703 - val_binary_accuracy: 0.6400 - val_loss: 0.7251\n",
            "Epoch 494/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9249 - loss: 0.2779 - val_binary_accuracy: 0.6400 - val_loss: 0.7110\n",
            "Epoch 495/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - binary_accuracy: 0.9165 - loss: 0.2958 - val_binary_accuracy: 0.6200 - val_loss: 0.7084\n",
            "Epoch 496/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9328 - loss: 0.2691 - val_binary_accuracy: 0.6600 - val_loss: 0.7498\n",
            "Epoch 497/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9050 - loss: 0.2839 - val_binary_accuracy: 0.6600 - val_loss: 0.7369\n",
            "Epoch 498/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9100 - loss: 0.2776 - val_binary_accuracy: 0.6400 - val_loss: 0.6959\n",
            "Epoch 499/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9244 - loss: 0.2803 - val_binary_accuracy: 0.6400 - val_loss: 0.6913\n",
            "Epoch 500/500\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9535 - loss: 0.2745 - val_binary_accuracy: 0.6600 - val_loss: 0.7698\n",
            "Training: ends at Sun, 03 Nov 2024 14:39:46\n",
            "Duration: 73.83 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fugflUT5JtCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be217f2b-ecca-4d73-fc92-8e3c6c1415ee"
      },
      "source": [
        "loss, acc = model.evaluate(x=train_x,y=train_y, batch_size=32)\n",
        "print('Train loss: %.4f - acc: %.4f' % (loss, acc))\n",
        "\n",
        "loss_, acc_ = model.evaluate(x=test_x,y=test_y, batch_size=32)\n",
        "print('Test loss: %.4f - acc: %.4f' % (loss_, acc_))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - binary_accuracy: 0.9290 - loss: 0.2718\n",
            "Train loss: 0.2859 - acc: 0.9043\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6483 - loss: 0.8052 \n",
            "Test loss: 0.7698 - acc: 0.6600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6CsWRrqJzFQ"
      },
      "source": [
        "# 2.0 Hyperparameter Tuning using Keras-Tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yff1zTsrLJ4J"
      },
      "source": [
        "The [Keras Tuner](https://github.com/keras-team/keras-tuner) is a library that helps you pick the optimal set of hyperparameters for your TensorFlow program. The process of selecting the right set of hyperparameters for your machine learning (ML) application is called **hyperparameter tuning** or **hypertuning**.\n",
        "\n",
        "Hyperparameters are the variables that govern the training process and the topology of an ML model. These variables remain constant over the training process and directly impact the performance of your ML program. Hyperparameters are of two types:\n",
        "1. **Model hyperparameters** which influence model selection such as the number and width of hidden layers\n",
        "2. **Algorithm hyperparameters** which influence the speed and quality of the learning algorithm such as the learning rate for Stochastic Gradient Descent (SGD) and the number of nearest neighbors for a k Nearest Neighbors (KNN) classifier, among others.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5YEL2H2Ax3e"
      },
      "source": [
        "## 2.1 Define the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md7FhKoYcuj7"
      },
      "source": [
        "\n",
        "When you build a model for hypertuning, you also define the hyperparameter search space in addition to the model architecture. The model you set up for hypertuning is called a **hypermodel**.\n",
        "\n",
        "You can define a hypermodel through two approaches:\n",
        "\n",
        "* By using a model builder function\n",
        "* By subclassing the `HyperModel` class of the Keras Tuner API\n",
        "\n",
        "You can also use two pre-defined `HyperModel` classes - [HyperXception](https://keras-team.github.io/keras-tuner/documentation/hypermodels/#hyperxception-class) and [HyperResNet](https://keras-team.github.io/keras-tuner/documentation/hypermodels/#hyperresnet-class) for computer vision applications.\n",
        "\n",
        "In this section, you use a model builder function to define the image classification model. The model builder function returns a compiled model and uses hyperparameters you define inline to hypertune the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Iosz7dctGf"
      },
      "source": [
        "def model_builder(hp):\n",
        "  # Instantiate a simple classification model\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 8-32\n",
        "  hp_units = hp.Int('units', min_value = 8, max_value = 32, step = 8)\n",
        "  model.add(tf.keras.layers.Dense(hp_units, activation=tf.nn.relu, dtype='float64'))\n",
        "  model.add(tf.keras.layers.Dense(8, activation=tf.nn.relu, dtype='float64'))\n",
        "  model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid, dtype='float64'))\n",
        "\n",
        "  # Instantiate a logistic loss function that expects integer targets.\n",
        "  loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "  # Instantiate an accuracy metric.\n",
        "  accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "  # Instantiate an optimizer.\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "\n",
        "  # configure the optimizer, loss, and metrics to monitor.\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8bYqKpDeBlB"
      },
      "source": [
        "## 2.2 Instantiate the tuner and perform hypertuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYX1lhvDeDoz"
      },
      "source": [
        "\n",
        "Instantiate the tuner to perform the hypertuning. The Keras Tuner has [four tuners available](https://keras-team.github.io/keras-tuner/documentation/tuners/) - `RandomSearch`, `Hyperband`, `BayesianOptimization`, and `Sklearn`.\n",
        "\n",
        "Notice that in previous subsection we're not fitting there, and we're returning the compiled model. Let's continue to build out the rest of our program first, then we'll make things more dynamic. Adding the dynamic bits will all happen in the **model_builder** function, but we will need some other code that will use this function now.  To start, we're going to import **RandomSearch** and after that we'll first define our tuner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOzyY-KLhQd5"
      },
      "source": [
        "from keras_tuner.tuners import RandomSearch"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4JXxAYAe67h"
      },
      "source": [
        "# path to store results\n",
        "LOG_DIR = f\"{int(time.time())}\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikjt5YbnepK5"
      },
      "source": [
        "tuner = RandomSearch(model_builder,\n",
        "                     objective='val_binary_accuracy',\n",
        "                     max_trials=4,  # how many model configurations would you like to test?\n",
        "                     executions_per_trial=1,  # how many trials per variation? (same model could perform differently)\n",
        "                     directory=LOG_DIR,\n",
        "                     project_name=\"my_first_tuner\"\n",
        "                     )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8LgEGSAhewb"
      },
      "source": [
        "- Your objective here probably should be **validation accuracy**, but you can choose from other things like **val_loss** for example.\n",
        "- **max_trials** allows you limit how many tests will be run. If you put 10 here, you will get 10 different tests (provided you've specified enough variability for 10 different combinations, anyway).\n",
        "- **executions_per_trial** might be 1, but you might also do many more like 3,5, or even 10.\n",
        "\n",
        "Basically, if you're just hunting for a model that works, then you should just do 1 trial per variation. If you're attempting to seek out 1-3% on **validation accuracy**, then you should run 3+ trials most likely per model, because each time a model runs, you should see some variation in final values. So this will just depend on what kind of a search you're doing (just trying to find something that works vs fine tuning...or anything in between)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJwb5NZgiWXt"
      },
      "source": [
        "Run the hyperparameter search. The arguments for the search method are the same as those used for [`tf.keras.model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).\n",
        "\n",
        "Before running the hyperparameter search, define a callback to clear the training outputs at the end of every training step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK6XNozXlJK7"
      },
      "source": [
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyNf7zRakAcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdee906-0ee0-4119-d570-dc2e52c0d291"
      },
      "source": [
        "tuner.search(train_x,\n",
        "             train_y,\n",
        "             epochs = 500,\n",
        "             verbose=1,\n",
        "             batch_size=32,\n",
        "             validation_data = (test_x, test_y),\n",
        "             callbacks = [ClearTrainingOutput()])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 4 Complete [00h 01m 00s]\n",
            "val_binary_accuracy: 0.7599999904632568\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.8199999928474426\n",
            "Total elapsed time: 00h 04m 04s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th3JZnM5kX_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de67b71-2109-424e-d9dd-9ccc2eef51a6"
      },
      "source": [
        "# print a summary of results\n",
        "tuner.results_summary(num_trials=10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in 1730655587/my_first_tuner\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_binary_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "units: 32\n",
            "Score: 0.8199999928474426\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "units: 16\n",
            "Score: 0.7799999713897705\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "units: 8\n",
            "Score: 0.7599999904632568\n",
            "\n",
            "Trial 3 summary\n",
            "Hyperparameters:\n",
            "units: 24\n",
            "Score: 0.7599999904632568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICBtBvvSm7AE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45af3fe6-3e00-4784-f393-efe04d368bfd"
      },
      "source": [
        "# best hyperparameters is a dictionary\n",
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units': 32}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O9cyI_kK0US",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951be263-e0ae-4e19-d25b-51b9e78ac472"
      },
      "source": [
        "# search space summary\n",
        "tuner.search_space_summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 1\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 32, 'step': 8, 'sampling': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfJ3aiJ5p9iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92617974-b10d-4c1a-abd7-c9e4feaffe59"
      },
      "source": [
        "print(f\"\"\"The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {tuner.get_best_hyperparameters()[0].values.get('units')}\"\"\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvyvW9oZwkgJ"
      },
      "source": [
        "## 2.3 Playing with search space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cIpO1GkxTgZ"
      },
      "source": [
        "We also can play with the search space in order to contain conditional hyperparameters. Below, we have a **for loop** creating a **tunable number of layers**, which themselves involve a tunable **units** parameter. This can be pushed to any level of parameter interdependency, including recursion. Note that all parameter names should be unique (here, in the loop over **i**, we name the inner parameters **'units_'** + **str(i)**)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZPJ9lSLyEfg"
      },
      "source": [
        "def model_builder_all(hp):\n",
        "  # Instantiate a simple classification model\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  # Create a tunable number of layers 1,2,3,4\n",
        "  for i in range(hp.Int('num_layers', 1, 4)):\n",
        "\n",
        "    # Tune the number of units in the Dense layer\n",
        "    # Choose an optimal value between 8-32\n",
        "    model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                                        min_value = 8,\n",
        "                                        max_value = 32,\n",
        "                                        step = 8),\n",
        "                                    # Tune the activation functions\n",
        "                                    activation= hp.Choice('dense_activation_' + str(i),\n",
        "                                                          values=['relu', 'tanh'],\n",
        "                                                          default='relu'),\n",
        "                                    dtype='float64'))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid, dtype='float64'))\n",
        "\n",
        "  # Instantiate a logistic loss function that expects integer targets.\n",
        "  loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "  # Instantiate an accuracy metric.\n",
        "  accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "  optimizer = hp.Choice('optimizer', ['adam', 'SGD'])\n",
        "  if optimizer == 'adam':\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=hp.Float('lrate_adam',\n",
        "                                                          min_value=1e-4,\n",
        "                                                          max_value=1e-2,\n",
        "                                                          sampling='LOG'))\n",
        "  else:\n",
        "    opt = tf.keras.optimizers.SGD(learning_rate=hp.Float('lrate_sgd',\n",
        "                                                          min_value=1e-4,\n",
        "                                                          max_value=1e-2,\n",
        "                                                          sampling='LOG'))\n",
        "\n",
        "  # configure the optimizer, loss, and metrics to monitor.\n",
        "  model.compile(optimizer=opt, loss=loss, metrics=[accuracy])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GuC7Drk2ZLC"
      },
      "source": [
        "# path to store results\n",
        "LOG_DIR = f\"{int(time.time())}\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc7BSy102ZLI"
      },
      "source": [
        "tuner_ = RandomSearch(model_builder_all,\n",
        "                     objective='val_binary_accuracy',\n",
        "                     max_trials=20,  # how many model configurations would you like to test?\n",
        "                     executions_per_trial=1,  # how many trials per variation? (same model could perform differently)\n",
        "                     directory=LOG_DIR,\n",
        "                     project_name=\"my_first_tuner\"\n",
        "                     )"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p39oHKAl2aXK"
      },
      "source": [
        "tuner_.search(train_x,\n",
        "             train_y,\n",
        "             epochs = 500,\n",
        "             # verbose = 0 (silent)\n",
        "             verbose=0,\n",
        "             batch_size=32,\n",
        "             validation_data = (test_x, test_y),\n",
        "             callbacks = [ClearTrainingOutput()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CNxpcdg3phN"
      },
      "source": [
        "tuner_.results_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPU-lmv_3AHD"
      },
      "source": [
        "tuner_.get_best_hyperparameters()[0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TUz0_MtWf9e"
      },
      "source": [
        "tuner_.search_space_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmAuZCk8gAbP"
      },
      "source": [
        "## 2.4 Retrain the model with the optimal hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZi_vqSUcX5p"
      },
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data\n",
        "best_hps = tuner_.get_best_hyperparameters()[0]\n",
        "model = tuner_.hypermodel.build(best_hps)\n",
        "model.fit(train_x, train_y, epochs = 500, validation_data = (test_x, test_y),batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8simDMO93_Cb"
      },
      "source": [
        "loss_, acc_ = model.evaluate(x=test_x,y=test_y, batch_size=32)\n",
        "print('Test loss: %.3f - acc: %.3f' % (loss_, acc_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyDo-xOti6_4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m25iq5vkgpg0"
      },
      "source": [
        "<mark>Exercise</mark>\n",
        "\n",
        "Hyperparameter tuning is a time-consuming task. The previous result was not so good. You can try to improve it the tuning considering:\n",
        "- Other [Tuners](https://keras-team.github.io/keras-tuner/documentation/tuners/): BayesianOptimization, Hyperband\n",
        "- Evaluate **max_trials** ranges over 100 or more?\n",
        "- **executions_per_trial** values in [2,3]?\n",
        "- How about you write an article on Medium about Keras Tuner?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BOmmZWxiInr"
      },
      "source": [
        "# PUT YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QL9wGBN363h"
      },
      "source": [
        "# 3.0 References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hfqjn0sXQVh"
      },
      "source": [
        "1. https://www.kaggle.com/fchollet/moa-keras-kerastuner-best-practices/\n",
        "2. https://www.kaggle.com/fchollet/titanic-keras-kerastuner-best-practices\n",
        "3. https://www.kaggle.com/fchollet/keras-kerastuner-best-practices\n",
        "4. https://pythonprogramming.net/keras-tuner-optimizing-neural-network-tutorial/\n",
        "5. https://github.com/keras-team/keras-tuner\n",
        "6. https://machinelearningmastery.com/autokeras-for-classification-and-regression/"
      ]
    }
  ]
}